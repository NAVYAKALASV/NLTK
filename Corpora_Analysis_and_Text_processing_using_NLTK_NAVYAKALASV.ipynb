{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BFNZXk11cOzC"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "import nltk\n",
        "import matplotlib as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from nltk.corpus import brown\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "brown.categories()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjTgcv6u2yKQ",
        "outputId": "c5d1b89a-e1f2-411e-8762-1b0a19b0f062"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(brown.words())#tokens"
      ],
      "metadata": {
        "id": "NVdkj9CL3miT",
        "outputId": "fd0105d5-6f15-4dc0-e4e3-f4674ac0e4bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1161192"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_words = 0\n",
        "with open(r'nlp.txt','r') as file:\n",
        "\tdata = file.read()\n",
        "\tlines = data.split()\n",
        "\tnumber_of_words += len(lines)\n",
        "print(number_of_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWFgmsWz4luC",
        "outputId": "c3467b8f-0310-42b6-e8f1-70ce0408dd83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"nlp.txt\", 'r', errors = 'ignore')\n",
        "x = f.read()\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "RxBp0uwWg0C_",
        "outputId": "a5261cce-4d2a-4522-b614-0675e1d685a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Penny was a little girl who lived in Alaska. It was ice-cold there. wait waited waiting waiter waits. \\nShe kept praying that she could play in the lush, green and warm gardens like we do but of course, she couldn\\'t. \\nHer father, like all the men there, didn\\'t have a job. He hunted seals and caught fishes as was the custom. \\nSo her father hadn\\'t even heard of money and even if he had money, there weren\\'t any aeroplanes to take them abroad. \\nNow somewhere near Penny\\'s house was a deep, dark forest. \\nEveryone was afraid to enter it. They said that whoever entered it would be sucked in by a great hole. \\nOne day, Penny was playing with her Eskimo friends when one of the boys shouted,\"Hey, I dare one of you to enter the magic forest.\" \\nNo one dared. Penny picked up a twig and threw it at the edge of the forest. Nothing happened. \\nPenny was astonished. It\\'s all a legend! We can play hide and seek in the woods if we want, she thought. \\nShe walked slowly towards the woods. It was getting colder and colder she took each step. She walked right into the middle of the forest. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "the_count = Counter(x)\n",
        "print(the_count)"
      ],
      "metadata": {
        "id": "p3OoXxIC68X5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a7fa04-aa51-48f2-83aa-ee8e42b39b22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({' ': 203, 'e': 126, 't': 72, 'a': 71, 'n': 56, 'h': 55, 'o': 55, 'd': 48, 's': 46, 'r': 41, 'i': 40, 'w': 33, 'l': 30, 'y': 20, '.': 19, 'g': 17, 'f': 17, 'u': 15, 'c': 14, 'k': 13, 'p': 12, ',': 10, 'm': 10, '\\n': 9, 'v': 6, 'b': 6, \"'\": 6, 'P': 5, 'I': 4, 'S': 4, 'H': 3, 'N': 3, 'E': 2, '\"': 2, 'A': 1, '-': 1, 'j': 1, 'T': 1, 'O': 1, '!': 1, 'W': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brown.words(categories='government')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYBInJnuaPzO",
        "outputId": "c6d37750-98af-4c48-df63-fe8e1f43bcf4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'Office', 'of', 'Business', 'Economics', '(', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "split_it = x.split()\n",
        "Counter = Counter(split_it)\n",
        "most_occur = Counter.most_common(4)\n",
        "print(most_occur)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu-4eOx-azSZ",
        "outputId": "d41d2ab5-26e9-4be4-979b-ecb66c6b5091"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 11), ('was', 8), ('a', 6), ('and', 6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y9xs9BePa_3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') \n",
        "nltk.download('wordnet') \n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "sentences= nltk.sent_tokenize(x)\n",
        "length= len(sentences)\n",
        "length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLT4y461a-uP",
        "outputId": "1c6f85a7-b984-4ea4-c643-a1659f330b44"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "#parsed corpora\n",
        "nltk.download('treebank')\n",
        "from nltk.corpus import treebank\n",
        "print(treebank.fileids())\n",
        "print(treebank.words('wsj_0003.mrg'))\n",
        "print(treebank.tagged_words('wsj_0003.mrg'))\n",
        "print(treebank.parsed_sents('wsj_0003.mrg')[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP27j_bUbdg4",
        "outputId": "7762121f-38c1-4009-95da-29ecd4133c3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['wsj_0001.mrg', 'wsj_0002.mrg', 'wsj_0003.mrg', 'wsj_0004.mrg', 'wsj_0005.mrg', 'wsj_0006.mrg', 'wsj_0007.mrg', 'wsj_0008.mrg', 'wsj_0009.mrg', 'wsj_0010.mrg', 'wsj_0011.mrg', 'wsj_0012.mrg', 'wsj_0013.mrg', 'wsj_0014.mrg', 'wsj_0015.mrg', 'wsj_0016.mrg', 'wsj_0017.mrg', 'wsj_0018.mrg', 'wsj_0019.mrg', 'wsj_0020.mrg', 'wsj_0021.mrg', 'wsj_0022.mrg', 'wsj_0023.mrg', 'wsj_0024.mrg', 'wsj_0025.mrg', 'wsj_0026.mrg', 'wsj_0027.mrg', 'wsj_0028.mrg', 'wsj_0029.mrg', 'wsj_0030.mrg', 'wsj_0031.mrg', 'wsj_0032.mrg', 'wsj_0033.mrg', 'wsj_0034.mrg', 'wsj_0035.mrg', 'wsj_0036.mrg', 'wsj_0037.mrg', 'wsj_0038.mrg', 'wsj_0039.mrg', 'wsj_0040.mrg', 'wsj_0041.mrg', 'wsj_0042.mrg', 'wsj_0043.mrg', 'wsj_0044.mrg', 'wsj_0045.mrg', 'wsj_0046.mrg', 'wsj_0047.mrg', 'wsj_0048.mrg', 'wsj_0049.mrg', 'wsj_0050.mrg', 'wsj_0051.mrg', 'wsj_0052.mrg', 'wsj_0053.mrg', 'wsj_0054.mrg', 'wsj_0055.mrg', 'wsj_0056.mrg', 'wsj_0057.mrg', 'wsj_0058.mrg', 'wsj_0059.mrg', 'wsj_0060.mrg', 'wsj_0061.mrg', 'wsj_0062.mrg', 'wsj_0063.mrg', 'wsj_0064.mrg', 'wsj_0065.mrg', 'wsj_0066.mrg', 'wsj_0067.mrg', 'wsj_0068.mrg', 'wsj_0069.mrg', 'wsj_0070.mrg', 'wsj_0071.mrg', 'wsj_0072.mrg', 'wsj_0073.mrg', 'wsj_0074.mrg', 'wsj_0075.mrg', 'wsj_0076.mrg', 'wsj_0077.mrg', 'wsj_0078.mrg', 'wsj_0079.mrg', 'wsj_0080.mrg', 'wsj_0081.mrg', 'wsj_0082.mrg', 'wsj_0083.mrg', 'wsj_0084.mrg', 'wsj_0085.mrg', 'wsj_0086.mrg', 'wsj_0087.mrg', 'wsj_0088.mrg', 'wsj_0089.mrg', 'wsj_0090.mrg', 'wsj_0091.mrg', 'wsj_0092.mrg', 'wsj_0093.mrg', 'wsj_0094.mrg', 'wsj_0095.mrg', 'wsj_0096.mrg', 'wsj_0097.mrg', 'wsj_0098.mrg', 'wsj_0099.mrg', 'wsj_0100.mrg', 'wsj_0101.mrg', 'wsj_0102.mrg', 'wsj_0103.mrg', 'wsj_0104.mrg', 'wsj_0105.mrg', 'wsj_0106.mrg', 'wsj_0107.mrg', 'wsj_0108.mrg', 'wsj_0109.mrg', 'wsj_0110.mrg', 'wsj_0111.mrg', 'wsj_0112.mrg', 'wsj_0113.mrg', 'wsj_0114.mrg', 'wsj_0115.mrg', 'wsj_0116.mrg', 'wsj_0117.mrg', 'wsj_0118.mrg', 'wsj_0119.mrg', 'wsj_0120.mrg', 'wsj_0121.mrg', 'wsj_0122.mrg', 'wsj_0123.mrg', 'wsj_0124.mrg', 'wsj_0125.mrg', 'wsj_0126.mrg', 'wsj_0127.mrg', 'wsj_0128.mrg', 'wsj_0129.mrg', 'wsj_0130.mrg', 'wsj_0131.mrg', 'wsj_0132.mrg', 'wsj_0133.mrg', 'wsj_0134.mrg', 'wsj_0135.mrg', 'wsj_0136.mrg', 'wsj_0137.mrg', 'wsj_0138.mrg', 'wsj_0139.mrg', 'wsj_0140.mrg', 'wsj_0141.mrg', 'wsj_0142.mrg', 'wsj_0143.mrg', 'wsj_0144.mrg', 'wsj_0145.mrg', 'wsj_0146.mrg', 'wsj_0147.mrg', 'wsj_0148.mrg', 'wsj_0149.mrg', 'wsj_0150.mrg', 'wsj_0151.mrg', 'wsj_0152.mrg', 'wsj_0153.mrg', 'wsj_0154.mrg', 'wsj_0155.mrg', 'wsj_0156.mrg', 'wsj_0157.mrg', 'wsj_0158.mrg', 'wsj_0159.mrg', 'wsj_0160.mrg', 'wsj_0161.mrg', 'wsj_0162.mrg', 'wsj_0163.mrg', 'wsj_0164.mrg', 'wsj_0165.mrg', 'wsj_0166.mrg', 'wsj_0167.mrg', 'wsj_0168.mrg', 'wsj_0169.mrg', 'wsj_0170.mrg', 'wsj_0171.mrg', 'wsj_0172.mrg', 'wsj_0173.mrg', 'wsj_0174.mrg', 'wsj_0175.mrg', 'wsj_0176.mrg', 'wsj_0177.mrg', 'wsj_0178.mrg', 'wsj_0179.mrg', 'wsj_0180.mrg', 'wsj_0181.mrg', 'wsj_0182.mrg', 'wsj_0183.mrg', 'wsj_0184.mrg', 'wsj_0185.mrg', 'wsj_0186.mrg', 'wsj_0187.mrg', 'wsj_0188.mrg', 'wsj_0189.mrg', 'wsj_0190.mrg', 'wsj_0191.mrg', 'wsj_0192.mrg', 'wsj_0193.mrg', 'wsj_0194.mrg', 'wsj_0195.mrg', 'wsj_0196.mrg', 'wsj_0197.mrg', 'wsj_0198.mrg', 'wsj_0199.mrg']\n",
            "['A', 'form', 'of', 'asbestos', 'once', 'used', '*', ...]\n",
            "[('A', 'DT'), ('form', 'NN'), ('of', 'IN'), ...]\n",
            "(S\n",
            "  (S-TPC-1\n",
            "    (NP-SBJ\n",
            "      (NP (NP (DT A) (NN form)) (PP (IN of) (NP (NN asbestos))))\n",
            "      (RRC\n",
            "        (ADVP-TMP (RB once))\n",
            "        (VP\n",
            "          (VBN used)\n",
            "          (NP (-NONE- *))\n",
            "          (S-CLR\n",
            "            (NP-SBJ (-NONE- *))\n",
            "            (VP\n",
            "              (TO to)\n",
            "              (VP\n",
            "                (VB make)\n",
            "                (NP (NNP Kent) (NN cigarette) (NNS filters))))))))\n",
            "    (VP\n",
            "      (VBZ has)\n",
            "      (VP\n",
            "        (VBN caused)\n",
            "        (NP\n",
            "          (NP (DT a) (JJ high) (NN percentage))\n",
            "          (PP (IN of) (NP (NN cancer) (NNS deaths)))\n",
            "          (PP-LOC\n",
            "            (IN among)\n",
            "            (NP\n",
            "              (NP (DT a) (NN group))\n",
            "              (PP\n",
            "                (IN of)\n",
            "                (NP\n",
            "                  (NP (NNS workers))\n",
            "                  (RRC\n",
            "                    (VP\n",
            "                      (VBN exposed)\n",
            "                      (NP (-NONE- *))\n",
            "                      (PP-CLR (TO to) (NP (PRP it)))\n",
            "                      (ADVP-TMP\n",
            "                        (NP\n",
            "                          (QP (RBR more) (IN than) (CD 30))\n",
            "                          (NNS years))\n",
            "                        (IN ago))))))))))))\n",
            "  (, ,)\n",
            "  (NP-SBJ (NNS researchers))\n",
            "  (VP (VBD reported) (SBAR (-NONE- 0) (S (-NONE- *T*-1))))\n",
            "  (. .))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#POS tagged corpora\n",
        "from nltk.corpus import brown\n",
        "print(brown.words())\n",
        "print(brown.tagged_words())\n",
        "print(brown.sents())\n",
        "print(brown.tagged_sents())\n",
        "print(brown.paras(categories='reviews'))\n",
        "print(brown.tagged_paras(categories='reviews'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arkrd-41c37U",
        "outputId": "bb36f2e7-8247-4d78-ee0e-d75df5cd5747"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n",
            "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n",
            "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n",
            "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]\n",
            "[[['It', 'is', 'not', 'news', 'that', 'Nathan', 'Milstein', 'is', 'a', 'wizard', 'of', 'the', 'violin', '.'], ['Certainly', 'not', 'in', 'Orchestra', 'Hall', 'where', 'he', 'has', 'played', 'countless', 'recitals', ',', 'and', 'where', 'Thursday', 'night', 'he', 'celebrated', 'his', '20th', 'season', 'with', 'the', 'Chicago', 'Symphony', 'Orchestra', ',', 'playing', 'the', 'Brahms', 'Concerto', 'with', 'his', 'own', 'slashing', ',', 'demon-ridden', 'cadenza', 'melting', 'into', 'the', 'high', ',', 'pale', ',', 'pure', 'and', 'lovely', 'song', 'with', 'which', 'a', 'violinist', 'unlocks', 'the', 'heart', 'of', 'the', 'music', ',', 'or', 'forever', 'finds', 'it', 'closed', '.']], [['There', 'was', 'about', 'that', 'song', 'something', 'incandescent', ',', 'for', 'this', 'Brahms', 'was', 'Milstein', 'at', 'white', 'heat', '.'], ['Not', 'the', 'noblest', 'performance', 'we', 'have', 'heard', 'him', 'play', ',', 'or', 'the', 'most', 'spacious', ',', 'or', 'even', 'the', 'most', 'eloquent', '.'], ['Those', 'would', 'be', 'reserved', 'for', 'the', \"orchestra's\", 'great', 'nights', 'when', 'the', 'soloist', 'can', 'surpass', 'himself', '.'], ['This', 'time', 'the', 'orchestra', 'gave', 'him', 'some', 'superb', 'support', 'fired', 'by', 'response', 'to', 'his', 'own', 'high', 'mood', '.'], ['But', 'he', 'had', 'in', 'Walter', 'Hendl', 'a', 'willing', 'conductor', 'able', 'only', 'up', 'to', 'a', 'point', '.']], ...]\n",
            "[[[('It', 'PPS'), ('is', 'BEZ'), ('not', '*'), ('news', 'NN'), ('that', 'CS'), ('Nathan', 'NP'), ('Milstein', 'NP'), ('is', 'BEZ'), ('a', 'AT'), ('wizard', 'NN'), ('of', 'IN'), ('the', 'AT'), ('violin', 'NN'), ('.', '.')], [('Certainly', 'RB'), ('not', '*'), ('in', 'IN'), ('Orchestra', 'NN-TL'), ('Hall', 'NN-TL'), ('where', 'WRB'), ('he', 'PPS'), ('has', 'HVZ'), ('played', 'VBN'), ('countless', 'JJ'), ('recitals', 'NNS'), (',', ','), ('and', 'CC'), ('where', 'WRB'), ('Thursday', 'NR'), ('night', 'NN'), ('he', 'PPS'), ('celebrated', 'VBD'), ('his', 'PP$'), ('20th', 'OD'), ('season', 'NN'), ('with', 'IN'), ('the', 'AT'), ('Chicago', 'NP-TL'), ('Symphony', 'NN-TL'), ('Orchestra', 'NN-TL'), (',', ','), ('playing', 'VBG'), ('the', 'AT'), ('Brahms', 'NP-TL'), ('Concerto', 'NN-TL'), ('with', 'IN'), ('his', 'PP$'), ('own', 'JJ'), ('slashing', 'VBG'), (',', ','), ('demon-ridden', 'JJ'), ('cadenza', 'NN'), ('melting', 'VBG'), ('into', 'IN'), ('the', 'AT'), ('high', 'JJ'), (',', ','), ('pale', 'JJ'), (',', ','), ('pure', 'JJ'), ('and', 'CC'), ('lovely', 'JJ'), ('song', 'NN'), ('with', 'IN'), ('which', 'WDT'), ('a', 'AT'), ('violinist', 'NN'), ('unlocks', 'VBZ'), ('the', 'AT'), ('heart', 'NN'), ('of', 'IN'), ('the', 'AT'), ('music', 'NN'), (',', ','), ('or', 'CC'), ('forever', 'RB'), ('finds', 'VBZ'), ('it', 'PPO'), ('closed', 'VBN'), ('.', '.')]], [[('There', 'EX'), ('was', 'BEDZ'), ('about', 'IN'), ('that', 'DT'), ('song', 'NN'), ('something', 'PN'), ('incandescent', 'JJ'), (',', ','), ('for', 'CS'), ('this', 'DT'), ('Brahms', 'NP'), ('was', 'BEDZ'), ('Milstein', 'NP'), ('at', 'IN'), ('white', 'JJ'), ('heat', 'NN'), ('.', '.')], [('Not', '*'), ('the', 'AT'), ('noblest', 'JJT'), ('performance', 'NN'), ('we', 'PPSS'), ('have', 'HV'), ('heard', 'VBN'), ('him', 'PPO'), ('play', 'VB'), (',', ','), ('or', 'CC'), ('the', 'AT'), ('most', 'QL'), ('spacious', 'JJ'), (',', ','), ('or', 'CC'), ('even', 'RB'), ('the', 'AT'), ('most', 'QL'), ('eloquent', 'JJ'), ('.', '.')], [('Those', 'DTS'), ('would', 'MD'), ('be', 'BE'), ('reserved', 'VBN'), ('for', 'IN'), ('the', 'AT'), (\"orchestra's\", 'NN$'), ('great', 'JJ'), ('nights', 'NNS'), ('when', 'WRB'), ('the', 'AT'), ('soloist', 'NN'), ('can', 'MD'), ('surpass', 'VB'), ('himself', 'PPL'), ('.', '.')], [('This', 'DT'), ('time', 'NN'), ('the', 'AT'), ('orchestra', 'NN'), ('gave', 'VBD'), ('him', 'PPO'), ('some', 'DTI'), ('superb', 'JJ'), ('support', 'NN'), ('fired', 'VBN'), ('by', 'IN'), ('response', 'NN'), ('to', 'IN'), ('his', 'PP$'), ('own', 'JJ'), ('high', 'JJ'), ('mood', 'NN'), ('.', '.')], [('But', 'CC'), ('he', 'PPS'), ('had', 'HVD'), ('in', 'IN'), ('Walter', 'NP'), ('Hendl', 'NP'), ('a', 'AT'), ('willing', 'JJ'), ('conductor', 'NN'), ('able', 'JJ'), ('only', 'RB'), ('up', 'IN'), ('to', 'IN'), ('a', 'AT'), ('point', 'NN'), ('.', '.')]], ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('indian')\n",
        "from nltk.corpus import indian\n",
        "print(indian.words()) \n",
        "print(indian.tagged_words()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzxquq6siLib",
        "outputId": "0694e2fd-0e7b-4847-d46e-bd0a55c36bd6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package indian to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['মহিষের', 'সন্তান', ':', 'তোড়া', 'উপজাতি', '৷', ...]\n",
            "[('মহিষের', 'NN'), ('সন্তান', 'NN'), (':', 'SYM'), ...]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/indian.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('universal_tagset')\n",
        "nltk.download('conll2000')\n",
        "nltk.download('switchboard')\n",
        "print(brown.tagged_sents(tagset='universal'))\n",
        "from nltk.corpus import conll2000, switchboard\n",
        "print(conll2000.tagged_words(tagset='universal'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61EfK1BLiaZf",
        "outputId": "3e86c504-b9f8-4534-ead9-8aa63af5c442"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]\n",
            "[('Confidence', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ...]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/switchboard.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "x = x.lower()"
      ],
      "metadata": {
        "id": "d8mAz7dttTum"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') \n",
        "nltk.download('wordnet') \n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "sent_tokens = nltk.sent_tokenize(x) \n",
        "word_tokens = nltk.word_tokenize(x) \n",
        "sent_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMNQQogvtVYD",
        "outputId": "cd485f48-9234-4ba8-8e9b-91fa8fc646a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['penny was a little girl who lived in alaska.',\n",
              " 'it was ice-cold there.',\n",
              " 'wait waited waiting waiter waits.',\n",
              " \"she kept praying that she could play in the lush, green and warm gardens like we do but of course, she couldn't.\",\n",
              " \"her father, like all the men there, didn't have a job.\",\n",
              " 'he hunted seals and caught fishes as was the custom.',\n",
              " \"so her father hadn't even heard of money and even if he had money, there weren't any aeroplanes to take them abroad.\",\n",
              " \"now somewhere near penny's house was a deep, dark forest.\",\n",
              " 'everyone was afraid to enter it.',\n",
              " 'they said that whoever entered it would be sucked in by a great hole.',\n",
              " 'one day, penny was playing with her eskimo friends when one of the boys shouted,\"hey, i dare one of you to enter the magic forest.\"',\n",
              " 'no one dared.',\n",
              " 'penny picked up a twig and threw it at the edge of the forest.',\n",
              " 'nothing happened.',\n",
              " 'penny was astonished.',\n",
              " \"it's all a legend!\",\n",
              " 'we can play hide and seek in the woods if we want, she thought.',\n",
              " 'she walked slowly towards the woods.',\n",
              " 'it was getting colder and colder she took each step.',\n",
              " 'she walked right into the middle of the forest.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sccH-9IYtnp2",
        "outputId": "899bfb59-d1bd-46d8-bf77-c155cf56d1eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['penny was a little girl who lived in alaska.',\n",
              " 'it was ice-cold there.',\n",
              " 'wait waited waiting waiter waits.',\n",
              " \"she kept praying that she could play in the lush, green and warm gardens like we do but of course, she couldn't.\",\n",
              " \"her father, like all the men there, didn't have a job.\",\n",
              " 'he hunted seals and caught fishes as was the custom.',\n",
              " \"so her father hadn't even heard of money and even if he had money, there weren't any aeroplanes to take them abroad.\",\n",
              " \"now somewhere near penny's house was a deep, dark forest.\",\n",
              " 'everyone was afraid to enter it.',\n",
              " 'they said that whoever entered it would be sucked in by a great hole.',\n",
              " 'one day, penny was playing with her eskimo friends when one of the boys shouted,\"hey, i dare one of you to enter the magic forest.\"',\n",
              " 'no one dared.',\n",
              " 'penny picked up a twig and threw it at the edge of the forest.',\n",
              " 'nothing happened.',\n",
              " 'penny was astonished.',\n",
              " \"it's all a legend!\",\n",
              " 'we can play hide and seek in the woods if we want, she thought.',\n",
              " 'she walked slowly towards the woods.',\n",
              " 'it was getting colder and colder she took each step.',\n",
              " 'she walked right into the middle of the forest.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFgOsZuittz9",
        "outputId": "50f73370-bab4-4e32-fbef-3e5915e0678e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['penny',\n",
              " 'was',\n",
              " 'a',\n",
              " 'little',\n",
              " 'girl',\n",
              " 'who',\n",
              " 'lived',\n",
              " 'in',\n",
              " 'alaska',\n",
              " '.',\n",
              " 'it',\n",
              " 'was',\n",
              " 'ice-cold',\n",
              " 'there',\n",
              " '.',\n",
              " 'wait',\n",
              " 'waited',\n",
              " 'waiting',\n",
              " 'waiter',\n",
              " 'waits',\n",
              " '.',\n",
              " 'she',\n",
              " 'kept',\n",
              " 'praying',\n",
              " 'that',\n",
              " 'she',\n",
              " 'could',\n",
              " 'play',\n",
              " 'in',\n",
              " 'the',\n",
              " 'lush',\n",
              " ',',\n",
              " 'green',\n",
              " 'and',\n",
              " 'warm',\n",
              " 'gardens',\n",
              " 'like',\n",
              " 'we',\n",
              " 'do',\n",
              " 'but',\n",
              " 'of',\n",
              " 'course',\n",
              " ',',\n",
              " 'she',\n",
              " 'could',\n",
              " \"n't\",\n",
              " '.',\n",
              " 'her',\n",
              " 'father',\n",
              " ',',\n",
              " 'like',\n",
              " 'all',\n",
              " 'the',\n",
              " 'men',\n",
              " 'there',\n",
              " ',',\n",
              " 'did',\n",
              " \"n't\",\n",
              " 'have',\n",
              " 'a',\n",
              " 'job',\n",
              " '.',\n",
              " 'he',\n",
              " 'hunted',\n",
              " 'seals',\n",
              " 'and',\n",
              " 'caught',\n",
              " 'fishes',\n",
              " 'as',\n",
              " 'was',\n",
              " 'the',\n",
              " 'custom',\n",
              " '.',\n",
              " 'so',\n",
              " 'her',\n",
              " 'father',\n",
              " 'had',\n",
              " \"n't\",\n",
              " 'even',\n",
              " 'heard',\n",
              " 'of',\n",
              " 'money',\n",
              " 'and',\n",
              " 'even',\n",
              " 'if',\n",
              " 'he',\n",
              " 'had',\n",
              " 'money',\n",
              " ',',\n",
              " 'there',\n",
              " 'were',\n",
              " \"n't\",\n",
              " 'any',\n",
              " 'aeroplanes',\n",
              " 'to',\n",
              " 'take',\n",
              " 'them',\n",
              " 'abroad',\n",
              " '.',\n",
              " 'now',\n",
              " 'somewhere',\n",
              " 'near',\n",
              " 'penny',\n",
              " \"'s\",\n",
              " 'house',\n",
              " 'was',\n",
              " 'a',\n",
              " 'deep',\n",
              " ',',\n",
              " 'dark',\n",
              " 'forest',\n",
              " '.',\n",
              " 'everyone',\n",
              " 'was',\n",
              " 'afraid',\n",
              " 'to',\n",
              " 'enter',\n",
              " 'it',\n",
              " '.',\n",
              " 'they',\n",
              " 'said',\n",
              " 'that',\n",
              " 'whoever',\n",
              " 'entered',\n",
              " 'it',\n",
              " 'would',\n",
              " 'be',\n",
              " 'sucked',\n",
              " 'in',\n",
              " 'by',\n",
              " 'a',\n",
              " 'great',\n",
              " 'hole',\n",
              " '.',\n",
              " 'one',\n",
              " 'day',\n",
              " ',',\n",
              " 'penny',\n",
              " 'was',\n",
              " 'playing',\n",
              " 'with',\n",
              " 'her',\n",
              " 'eskimo',\n",
              " 'friends',\n",
              " 'when',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'boys',\n",
              " 'shouted',\n",
              " ',',\n",
              " \"''\",\n",
              " 'hey',\n",
              " ',',\n",
              " 'i',\n",
              " 'dare',\n",
              " 'one',\n",
              " 'of',\n",
              " 'you',\n",
              " 'to',\n",
              " 'enter',\n",
              " 'the',\n",
              " 'magic',\n",
              " 'forest',\n",
              " '.',\n",
              " \"''\",\n",
              " 'no',\n",
              " 'one',\n",
              " 'dared',\n",
              " '.',\n",
              " 'penny',\n",
              " 'picked',\n",
              " 'up',\n",
              " 'a',\n",
              " 'twig',\n",
              " 'and',\n",
              " 'threw',\n",
              " 'it',\n",
              " 'at',\n",
              " 'the',\n",
              " 'edge',\n",
              " 'of',\n",
              " 'the',\n",
              " 'forest',\n",
              " '.',\n",
              " 'nothing',\n",
              " 'happened',\n",
              " '.',\n",
              " 'penny',\n",
              " 'was',\n",
              " 'astonished',\n",
              " '.',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'all',\n",
              " 'a',\n",
              " 'legend',\n",
              " '!',\n",
              " 'we',\n",
              " 'can',\n",
              " 'play',\n",
              " 'hide',\n",
              " 'and',\n",
              " 'seek',\n",
              " 'in',\n",
              " 'the',\n",
              " 'woods',\n",
              " 'if',\n",
              " 'we',\n",
              " 'want',\n",
              " ',',\n",
              " 'she',\n",
              " 'thought',\n",
              " '.',\n",
              " 'she',\n",
              " 'walked',\n",
              " 'slowly',\n",
              " 'towards',\n",
              " 'the',\n",
              " 'woods',\n",
              " '.',\n",
              " 'it',\n",
              " 'was',\n",
              " 'getting',\n",
              " 'colder',\n",
              " 'and',\n",
              " 'colder',\n",
              " 'she',\n",
              " 'took',\n",
              " 'each',\n",
              " 'step',\n",
              " '.',\n",
              " 'she',\n",
              " 'walked',\n",
              " 'right',\n",
              " 'into',\n",
              " 'the',\n",
              " 'middle',\n",
              " 'of',\n",
              " 'the',\n",
              " 'forest',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(x)\n",
        "filtered_text = [t for t in tokens if not t in stopwords.words(\"english\")]\n",
        "print(\" \".join(filtered_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI2U8CgvtwTX",
        "outputId": "d6fba148-7d4f-4b41-9cdd-0803f8021de0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "penny little girl lived alaska . ice-cold . wait waited waiting waiter waits . kept praying could play lush , green warm gardens like course , could n't . father , like men , n't job . hunted seals caught fishes custom . father n't even heard money even money , n't aeroplanes take abroad . somewhere near penny 's house deep , dark forest . everyone afraid enter . said whoever entered would sucked great hole . one day , penny playing eskimo friends one boys shouted , '' hey , dare one enter magic forest . '' one dared . penny picked twig threw edge forest . nothing happened . penny astonished . 's legend ! play hide seek woods want , thought . walked slowly towards woods . getting colder colder took step . walked right middle forest .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd \n",
        "ps = PorterStemmer()\n",
        "tokens = word_tokenize(x)\n",
        "print(tokens)\n",
        "stemmed = []\n",
        "for token in tokens:\n",
        "     stemmed_word = ps.stem(token)\n",
        "     stemmed.append(stemmed_word)\n",
        "print(stemmed)\n",
        "df = pd.DataFrame(data={\"tokens\":tokens, \"stemmed\": stemmed})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ4pw9iwuX3l",
        "outputId": "60aa86d6-372b-40ae-a554-ab4da9d8566d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['penny', 'was', 'a', 'little', 'girl', 'who', 'lived', 'in', 'alaska', '.', 'it', 'was', 'ice-cold', 'there', '.', 'wait', 'waited', 'waiting', 'waiter', 'waits', '.', 'she', 'kept', 'praying', 'that', 'she', 'could', 'play', 'in', 'the', 'lush', ',', 'green', 'and', 'warm', 'gardens', 'like', 'we', 'do', 'but', 'of', 'course', ',', 'she', 'could', \"n't\", '.', 'her', 'father', ',', 'like', 'all', 'the', 'men', 'there', ',', 'did', \"n't\", 'have', 'a', 'job', '.', 'he', 'hunted', 'seals', 'and', 'caught', 'fishes', 'as', 'was', 'the', 'custom', '.', 'so', 'her', 'father', 'had', \"n't\", 'even', 'heard', 'of', 'money', 'and', 'even', 'if', 'he', 'had', 'money', ',', 'there', 'were', \"n't\", 'any', 'aeroplanes', 'to', 'take', 'them', 'abroad', '.', 'now', 'somewhere', 'near', 'penny', \"'s\", 'house', 'was', 'a', 'deep', ',', 'dark', 'forest', '.', 'everyone', 'was', 'afraid', 'to', 'enter', 'it', '.', 'they', 'said', 'that', 'whoever', 'entered', 'it', 'would', 'be', 'sucked', 'in', 'by', 'a', 'great', 'hole', '.', 'one', 'day', ',', 'penny', 'was', 'playing', 'with', 'her', 'eskimo', 'friends', 'when', 'one', 'of', 'the', 'boys', 'shouted', ',', \"''\", 'hey', ',', 'i', 'dare', 'one', 'of', 'you', 'to', 'enter', 'the', 'magic', 'forest', '.', \"''\", 'no', 'one', 'dared', '.', 'penny', 'picked', 'up', 'a', 'twig', 'and', 'threw', 'it', 'at', 'the', 'edge', 'of', 'the', 'forest', '.', 'nothing', 'happened', '.', 'penny', 'was', 'astonished', '.', 'it', \"'s\", 'all', 'a', 'legend', '!', 'we', 'can', 'play', 'hide', 'and', 'seek', 'in', 'the', 'woods', 'if', 'we', 'want', ',', 'she', 'thought', '.', 'she', 'walked', 'slowly', 'towards', 'the', 'woods', '.', 'it', 'was', 'getting', 'colder', 'and', 'colder', 'she', 'took', 'each', 'step', '.', 'she', 'walked', 'right', 'into', 'the', 'middle', 'of', 'the', 'forest', '.']\n",
            "['penni', 'wa', 'a', 'littl', 'girl', 'who', 'live', 'in', 'alaska', '.', 'it', 'wa', 'ice-cold', 'there', '.', 'wait', 'wait', 'wait', 'waiter', 'wait', '.', 'she', 'kept', 'pray', 'that', 'she', 'could', 'play', 'in', 'the', 'lush', ',', 'green', 'and', 'warm', 'garden', 'like', 'we', 'do', 'but', 'of', 'cours', ',', 'she', 'could', \"n't\", '.', 'her', 'father', ',', 'like', 'all', 'the', 'men', 'there', ',', 'did', \"n't\", 'have', 'a', 'job', '.', 'he', 'hunt', 'seal', 'and', 'caught', 'fish', 'as', 'wa', 'the', 'custom', '.', 'so', 'her', 'father', 'had', \"n't\", 'even', 'heard', 'of', 'money', 'and', 'even', 'if', 'he', 'had', 'money', ',', 'there', 'were', \"n't\", 'ani', 'aeroplan', 'to', 'take', 'them', 'abroad', '.', 'now', 'somewher', 'near', 'penni', \"'s\", 'hous', 'wa', 'a', 'deep', ',', 'dark', 'forest', '.', 'everyon', 'wa', 'afraid', 'to', 'enter', 'it', '.', 'they', 'said', 'that', 'whoever', 'enter', 'it', 'would', 'be', 'suck', 'in', 'by', 'a', 'great', 'hole', '.', 'one', 'day', ',', 'penni', 'wa', 'play', 'with', 'her', 'eskimo', 'friend', 'when', 'one', 'of', 'the', 'boy', 'shout', ',', \"''\", 'hey', ',', 'i', 'dare', 'one', 'of', 'you', 'to', 'enter', 'the', 'magic', 'forest', '.', \"''\", 'no', 'one', 'dare', '.', 'penni', 'pick', 'up', 'a', 'twig', 'and', 'threw', 'it', 'at', 'the', 'edg', 'of', 'the', 'forest', '.', 'noth', 'happen', '.', 'penni', 'wa', 'astonish', '.', 'it', \"'s\", 'all', 'a', 'legend', '!', 'we', 'can', 'play', 'hide', 'and', 'seek', 'in', 'the', 'wood', 'if', 'we', 'want', ',', 'she', 'thought', '.', 'she', 'walk', 'slowli', 'toward', 'the', 'wood', '.', 'it', 'wa', 'get', 'colder', 'and', 'colder', 'she', 'took', 'each', 'step', '.', 'she', 'walk', 'right', 'into', 'the', 'middl', 'of', 'the', 'forest', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(x)\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LdbLwXL0Mpz",
        "outputId": "26a70f5b-5e0d-42c4-8225-98910b008870"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Lemma               \n",
            "penny               penny               \n",
            "was                 wa                  \n",
            "a                   a                   \n",
            "little              little              \n",
            "girl                girl                \n",
            "who                 who                 \n",
            "lived               lived               \n",
            "in                  in                  \n",
            "alaska              alaska              \n",
            "it                  it                  \n",
            "was                 wa                  \n",
            "ice-cold            ice-cold            \n",
            "there               there               \n",
            "wait                wait                \n",
            "waited              waited              \n",
            "waiting             waiting             \n",
            "waiter              waiter              \n",
            "waits               wait                \n",
            "she                 she                 \n",
            "kept                kept                \n",
            "praying             praying             \n",
            "that                that                \n",
            "she                 she                 \n",
            "could               could               \n",
            "play                play                \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "lush                lush                \n",
            "green               green               \n",
            "and                 and                 \n",
            "warm                warm                \n",
            "gardens             garden              \n",
            "like                like                \n",
            "we                  we                  \n",
            "do                  do                  \n",
            "but                 but                 \n",
            "of                  of                  \n",
            "course              course              \n",
            "she                 she                 \n",
            "could               could               \n",
            "n't                 n't                 \n",
            "her                 her                 \n",
            "father              father              \n",
            "like                like                \n",
            "all                 all                 \n",
            "the                 the                 \n",
            "men                 men                 \n",
            "there               there               \n",
            "did                 did                 \n",
            "n't                 n't                 \n",
            "have                have                \n",
            "a                   a                   \n",
            "job                 job                 \n",
            "he                  he                  \n",
            "hunted              hunted              \n",
            "seals               seal                \n",
            "and                 and                 \n",
            "caught              caught              \n",
            "fishes              fish                \n",
            "as                  a                   \n",
            "was                 wa                  \n",
            "the                 the                 \n",
            "custom              custom              \n",
            "so                  so                  \n",
            "her                 her                 \n",
            "father              father              \n",
            "had                 had                 \n",
            "n't                 n't                 \n",
            "even                even                \n",
            "heard               heard               \n",
            "of                  of                  \n",
            "money               money               \n",
            "and                 and                 \n",
            "even                even                \n",
            "if                  if                  \n",
            "he                  he                  \n",
            "had                 had                 \n",
            "money               money               \n",
            "there               there               \n",
            "were                were                \n",
            "n't                 n't                 \n",
            "any                 any                 \n",
            "aeroplanes          aeroplane           \n",
            "to                  to                  \n",
            "take                take                \n",
            "them                them                \n",
            "abroad              abroad              \n",
            "now                 now                 \n",
            "somewhere           somewhere           \n",
            "near                near                \n",
            "penny               penny               \n",
            "'s                  's                  \n",
            "house               house               \n",
            "was                 wa                  \n",
            "a                   a                   \n",
            "deep                deep                \n",
            "dark                dark                \n",
            "forest              forest              \n",
            "everyone            everyone            \n",
            "was                 wa                  \n",
            "afraid              afraid              \n",
            "to                  to                  \n",
            "enter               enter               \n",
            "it                  it                  \n",
            "they                they                \n",
            "said                said                \n",
            "that                that                \n",
            "whoever             whoever             \n",
            "entered             entered             \n",
            "it                  it                  \n",
            "would               would               \n",
            "be                  be                  \n",
            "sucked              sucked              \n",
            "in                  in                  \n",
            "by                  by                  \n",
            "a                   a                   \n",
            "great               great               \n",
            "hole                hole                \n",
            "one                 one                 \n",
            "day                 day                 \n",
            "penny               penny               \n",
            "was                 wa                  \n",
            "playing             playing             \n",
            "with                with                \n",
            "her                 her                 \n",
            "eskimo              eskimo              \n",
            "friends             friend              \n",
            "when                when                \n",
            "one                 one                 \n",
            "of                  of                  \n",
            "the                 the                 \n",
            "boys                boy                 \n",
            "shouted             shouted             \n",
            "''                  ''                  \n",
            "hey                 hey                 \n",
            "i                   i                   \n",
            "dare                dare                \n",
            "one                 one                 \n",
            "of                  of                  \n",
            "you                 you                 \n",
            "to                  to                  \n",
            "enter               enter               \n",
            "the                 the                 \n",
            "magic               magic               \n",
            "forest              forest              \n",
            "''                  ''                  \n",
            "no                  no                  \n",
            "one                 one                 \n",
            "dared               dared               \n",
            "penny               penny               \n",
            "picked              picked              \n",
            "up                  up                  \n",
            "a                   a                   \n",
            "twig                twig                \n",
            "and                 and                 \n",
            "threw               threw               \n",
            "it                  it                  \n",
            "at                  at                  \n",
            "the                 the                 \n",
            "edge                edge                \n",
            "of                  of                  \n",
            "the                 the                 \n",
            "forest              forest              \n",
            "nothing             nothing             \n",
            "happened            happened            \n",
            "penny               penny               \n",
            "was                 wa                  \n",
            "astonished          astonished          \n",
            "it                  it                  \n",
            "'s                  's                  \n",
            "all                 all                 \n",
            "a                   a                   \n",
            "legend              legend              \n",
            "we                  we                  \n",
            "can                 can                 \n",
            "play                play                \n",
            "hide                hide                \n",
            "and                 and                 \n",
            "seek                seek                \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "woods               wood                \n",
            "if                  if                  \n",
            "we                  we                  \n",
            "want                want                \n",
            "she                 she                 \n",
            "thought             thought             \n",
            "she                 she                 \n",
            "walked              walked              \n",
            "slowly              slowly              \n",
            "towards             towards             \n",
            "the                 the                 \n",
            "woods               wood                \n",
            "it                  it                  \n",
            "was                 wa                  \n",
            "getting             getting             \n",
            "colder              colder              \n",
            "and                 and                 \n",
            "colder              colder              \n",
            "she                 she                 \n",
            "took                took                \n",
            "each                each                \n",
            "step                step                \n",
            "she                 she                 \n",
            "walked              walked              \n",
            "right               right               \n",
            "into                into                \n",
            "the                 the                 \n",
            "middle              middle              \n",
            "of                  of                  \n",
            "the                 the                 \n",
            "forest              forest              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokenized = sent_tokenize(x)\n",
        "for i in tokenized:\n",
        "\twordsList = nltk.word_tokenize(i)\n",
        "\twordsList = [w for w in wordsList if not w in stop_words]\n",
        "\ttagged = nltk.pos_tag(wordsList)\n",
        "\tprint(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBVAh5e60mxE",
        "outputId": "79ce40c9-9050-437f-86f4-a1310eb53e68"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('penny', 'JJ'), ('little', 'JJ'), ('girl', 'NN'), ('lived', 'VBD'), ('alaska', 'NN'), ('.', '.')]\n",
            "[('ice-cold', 'NN'), ('.', '.')]\n",
            "[('wait', 'NN'), ('waited', 'VBD'), ('waiting', 'VBG'), ('waiter', 'NN'), ('waits', 'NNS'), ('.', '.')]\n",
            "[('kept', 'NNS'), ('praying', 'VBG'), ('could', 'MD'), ('play', 'VB'), ('lush', 'RB'), (',', ','), ('green', 'JJ'), ('warm', 'NN'), ('gardens', 'NNS'), ('like', 'IN'), ('course', 'NN'), (',', ','), ('could', 'MD'), (\"n't\", 'RB'), ('.', '.')]\n",
            "[('father', 'RB'), (',', ','), ('like', 'IN'), ('men', 'NNS'), (',', ','), (\"n't\", 'RB'), ('job', 'NN'), ('.', '.')]\n",
            "[('hunted', 'VBN'), ('seals', 'NNS'), ('caught', 'VBD'), ('fishes', 'NNS'), ('custom', 'NN'), ('.', '.')]\n",
            "[('father', 'NN'), (\"n't\", 'RB'), ('even', 'RB'), ('heard', 'VB'), ('money', 'NN'), ('even', 'RB'), ('money', 'NN'), (',', ','), (\"n't\", 'RB'), ('aeroplanes', 'NNS'), ('take', 'VB'), ('abroad', 'RB'), ('.', '.')]\n",
            "[('somewhere', 'RB'), ('near', 'IN'), ('penny', 'NN'), (\"'s\", 'POS'), ('house', 'NN'), ('deep', 'NN'), (',', ','), ('dark', 'JJ'), ('forest', 'NN'), ('.', '.')]\n",
            "[('everyone', 'NN'), ('afraid', 'JJ'), ('enter', 'NN'), ('.', '.')]\n",
            "[('said', 'VBD'), ('whoever', 'WP'), ('entered', 'VBD'), ('would', 'MD'), ('sucked', 'VB'), ('great', 'JJ'), ('hole', 'NN'), ('.', '.')]\n",
            "[('one', 'CD'), ('day', 'NN'), (',', ','), ('penny', 'JJ'), ('playing', 'VBG'), ('eskimo', 'JJ'), ('friends', 'NNS'), ('one', 'CD'), ('boys', 'NN'), ('shouted', 'VBD'), (',', ','), (\"''\", \"''\"), ('hey', 'NN'), (',', ','), ('dare', 'VB'), ('one', 'CD'), ('enter', 'NN'), ('magic', 'JJ'), ('forest', 'NN'), ('.', '.'), (\"''\", \"''\")]\n",
            "[('one', 'CD'), ('dared', 'VBN'), ('.', '.')]\n",
            "[('penny', 'NN'), ('picked', 'VBD'), ('twig', 'JJ'), ('threw', 'NN'), ('edge', 'NN'), ('forest', 'NN'), ('.', '.')]\n",
            "[('nothing', 'NN'), ('happened', 'VBD'), ('.', '.')]\n",
            "[('penny', 'NN'), ('astonished', 'VBD'), ('.', '.')]\n",
            "[(\"'s\", 'POS'), ('legend', 'NN'), ('!', '.')]\n",
            "[('play', 'NN'), ('hide', 'NN'), ('seek', 'VBP'), ('woods', 'NNS'), ('want', 'VBP'), (',', ','), ('thought', 'VBN'), ('.', '.')]\n",
            "[('walked', 'VBN'), ('slowly', 'RB'), ('towards', 'NNS'), ('woods', 'NNS'), ('.', '.')]\n",
            "[('getting', 'VBG'), ('colder', 'NN'), ('colder', 'NN'), ('took', 'VBD'), ('step', 'NN'), ('.', '.')]\n",
            "[('walked', 'VBN'), ('right', 'JJ'), ('middle', 'NN'), ('forest', 'JJS'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}